name: tpu_like

memories:
  rf_128B:
    size: 1024
    r_bw: 8
    w_bw: 8
    r_cost: 0.095
    w_cost: 0.095
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    auto_cost_extraction: False
    operands: [I2]
    ports:
      - fh: w_port_1
        tl: r_port_1
    served_dimensions: [] # Fully unrolled over all multipliers

  rf_2B:
    size: 16
    r_bw: 16
    w_bw: 16
    r_cost: 0.021
    w_cost: 0.021
    area: 0
    r_port: 2
    w_port: 2
    rw_port: 0
    latency: 1
    operands: [O]
    ports:
      - fh: w_port_1
        tl: r_port_1
        fl: w_port_2
        th: r_port_2
    served_dimensions: [D2]

  sram_2MB:
    size: 16777216
    r_bw: 2048
    w_bw: 2048
    r_cost: 416.16
    w_cost: 378.4
    area: 0
    r_port: 1
    w_port: 1
    rw_port: 0
    latency: 1
    min_r_granularity: 64
    min_w_granularity: 64
    operands: [I1, O]
    ports:
      - fh: w_port_1
        tl: r_port_1
      - fh: w_port_1
        tl: r_port_1
        fl: w_port_1
        th: r_port_1
    served_dimensions: [D1, D2]

  dram:
    size: 10000000000
    r_bw: 64
    w_bw: 64
    r_cost: 700
    w_cost: 750
    area: 0
    r_port: 0
    w_port: 0
    rw_port: 1
    latency: 1
    operands: [I1, I2, O]
    ports:
      - fh: rw_port_1
        tl: rw_port_1
      - fh: rw_port_1
        tl: rw_port_1
      - fh: rw_port_1
        tl: rw_port_1
        fl: rw_port_1
        th: rw_port_1
    served_dimensions: [D1, D2]

operational_array:
  input_precision: [8, 8]
  multiplier_energy: 0.04 # pJ
  multiplier_area: 1 # unit
  dimensions: [D1, D2]
  sizes: [32, 32]
