<!DOCTYPE html> <html lang=en > <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=viewport  content="width=device-width, initial-scale=1" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="_static/stylesheets/application.css"/> <link rel=stylesheet  href="_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="_static/fonts/material-icons.css"/> <meta name=theme-color  content="#3f51b5"> <script src="_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXX"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-XXXXX'); </script> <title>Hardware Architecture &#8212; ZigZag 2.0.0 documentation</title> <link rel=stylesheet  type="text/css" href="_static/pygments.css?v=83e35b93" /> <link rel=stylesheet  type="text/css" href="_static/material.css?v=79c92029" /> <script data-url_root="./" id=documentation_options  src="_static/documentation_options.js?v=73cda6fb"></script> <script src="_static/doctools.js?v=888ff710"></script> <script src="_static/sphinx_highlight.js?v=4825356b"></script> <link rel=icon  href="_static/zigzag_logo_white_32x32.svg"/> <link rel=index  title=Index  href=genindex.html  /> <link rel=search  title=Search  href=search.html  /> <link rel=next  title=Mapping  href=mapping.html  /> <link rel=prev  title=Workload  href=workload.html  /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=grey> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#hardware" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href=index.html  title="ZigZag 2.0.0 documentation" class="md-header-nav__button md-logo"> &nbsp; </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >ZigZag Framework</span> <span class=md-header-nav__topic > Hardware Architecture </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action=search.html  method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=""Search"" autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source > <a href="https://github.com/kuleuven-micas/zigzag" title="Go to repository" class=md-source  data-md-source=github > <div class=md-source__icon > <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width=28  height=28 > <use xlink:href="#__github" width=24  height=24 ></use> </svg> </div> <div class=md-source__repository > ZigZag Framework </div> </a> </div> </div> <script src="_static/javascripts/version_dropdown.js"></script> <script> var json_loc = ""versions.json"", target_loc = "../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href=index.html  class=md-tabs__link >ZigZag 2.0.0 documentation</a> <li class=md-tabs__item ><a href=user-guide.html  class=md-tabs__link >User Guide</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href=index.html  title="ZigZag 2.0.0 documentation" class="md-nav__button md-logo"> <img src="_static/" alt=" logo" width=48  height=48 > </a> <a href=index.html  title="ZigZag 2.0.0 documentation">ZigZag Framework</a> </label> <div class=md-nav__source > <a href="https://github.com/kuleuven-micas/zigzag" title="Go to repository" class=md-source  data-md-source=github > <div class=md-source__icon > <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width=28  height=28 > <use xlink:href="#__github" width=24  height=24 ></use> </svg> </div> <div class=md-source__repository > ZigZag Framework </div> </a> </div> <ul class=md-nav__list > <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Contents:</span></span> <li class=md-nav__item > <a href=installation.html  class=md-nav__link >Installing ZigZag</a> <li class=md-nav__item > <a href=getting-started.html  class=md-nav__link >Getting Started</a> <li class=md-nav__item > <a href=api.html  class=md-nav__link >ZigZag API</a> <li class=md-nav__item > <a href=user-guide.html  class=md-nav__link >User Guide</a> <ul class=md-nav__list > <li class=md-nav__item > <a href=workload.html  class=md-nav__link >Workload</a> <li class=md-nav__item > <input class="md-toggle md-nav__toggle" data-md-toggle=toc  type=checkbox  id=__toc > <label class="md-nav__link md-nav__link--active" for=__toc > Hardware Architecture </label> <a href="#" class="md-nav__link md-nav__link--active">Hardware Architecture</a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >"Contents"</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#hardware--page-root" class=md-nav__link >Hardware Architecture</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#operational-unit" class=md-nav__link >Operational Unit</a> <li class=md-nav__item ><a href="#operational-array" class=md-nav__link >Operational Array</a> <li class=md-nav__item ><a href="#memory-instance" class=md-nav__link >Memory Instance</a> <li class=md-nav__item ><a href="#memory-hierarchy" class=md-nav__link >Memory Hierarchy</a> <li class=md-nav__item ><a href="#core" class=md-nav__link >Core</a> <li class=md-nav__item ><a href="#hw-accelerator-model" class=md-nav__link >HW Accelerator Model</a> <li class=md-nav__item ><a href="#modelled-examples" class=md-nav__link >Modelled examples</a> <li class=md-nav__item ><a href="#specific-settings" class=md-nav__link >Specific settings</a> <li class=md-nav__item ><a href="#references" class=md-nav__link >References</a> </ul> </nav> <li class=md-nav__item ><a class=md-nav__extra_link  href="_sources/hardware.rst.txt">Show Source</a> </ul> </nav> <li class=md-nav__item > <a href=mapping.html  class=md-nav__link >Mapping</a> <li class=md-nav__item > <a href=stages.html  class=md-nav__link >Stages</a> <li class=md-nav__item > <a href=outputs.html  class=md-nav__link >Outputs</a> <li class=md-nav__item > <a href=visualization.html  class=md-nav__link >Visualization</a> </ul> <li class=md-nav__item > <a href=future.html  class=md-nav__link >Future changes</a> <li class=md-nav__item > <a href=contribute.html  class=md-nav__link >Contribute</a> <li class=md-nav__item > <a href=publications.html  class=md-nav__link >Publications</a> <li class=md-nav__item > <a href=code-documentation.html  class=md-nav__link >Code Documentation</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >"Contents"</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#hardware--page-root" class=md-nav__link >Hardware Architecture</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#operational-unit" class=md-nav__link >Operational Unit</a> <li class=md-nav__item ><a href="#operational-array" class=md-nav__link >Operational Array</a> <li class=md-nav__item ><a href="#memory-instance" class=md-nav__link >Memory Instance</a> <li class=md-nav__item ><a href="#memory-hierarchy" class=md-nav__link >Memory Hierarchy</a> <li class=md-nav__item ><a href="#core" class=md-nav__link >Core</a> <li class=md-nav__item ><a href="#hw-accelerator-model" class=md-nav__link >HW Accelerator Model</a> <li class=md-nav__item ><a href="#modelled-examples" class=md-nav__link >Modelled examples</a> <li class=md-nav__item ><a href="#specific-settings" class=md-nav__link >Specific settings</a> <li class=md-nav__item ><a href="#references" class=md-nav__link >References</a> </ul> </nav> <li class=md-nav__item ><a class=md-nav__extra_link  href="_sources/hardware.rst.txt">Show Source</a> <li id=searchbox  class=md-nav__item > </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <section id=hardware-architecture > <h1 id=hardware--page-root >Hardware Architecture<a class=headerlink  href="#hardware--page-root" title="Permalink to this heading">¶</a></h1> <p>In this section, we introduce the general concept of how HW accelerators are modeled within ZigZag and the different well-known accelerators we provide as examples. We start from the smallest building block defined in ZigZag and work our way up towards an accelerator.</p> <section id=operational-unit > <h2 id=operational-unit >Operational Unit<a class=headerlink  href="#operational-unit" title="Permalink to this heading">¶</a></h2> <p>Accelerating inference of a NN requires the execution of multiplications and summations (accumulations) across multiple intermediate data (activations) using trained parameters (weights). The operational unit, typically a Multiplier, executes the multiplication of two data elements, typically an activation and a weight.</p> <a class="reference internal image-reference" href="_images/operational-unit.jpg"><img alt="_images/operational-unit.jpg" src="_images/operational-unit.jpg" style="width: 400px;"/></a> <p>The operational unit object has the following attributes:</p> <ul class=simple > <li><p><strong>input_precision</strong>: List of input operand (data) precision in the number of bits for each input operand (typically there are two input operands for a Multiplier).</p> <li><p><strong>output_precision</strong>: The bit precision of the operation’s output (e.g., for a multiplier, the output_precision is auto-set to be the sum of two input operands’ precision).</p> <li><p><strong>energy_cost</strong>: Energy of executing a single operation (e.g., a multiplication).</p> <li><p><strong>area</strong>: The HW area overhead of a single operational unit (e.g., a multiplier).</p> </ul> </section> <section id=operational-array > <h2 id=operational-array >Operational Array<a class=headerlink  href="#operational-array" title="Permalink to this heading">¶</a></h2> <p>Inferencing a NN typically requires millions of operations, and an accelerator typically includes an array of operational units that can execute these operations in parallel. This can significantly speed up the computations, as well as increase energy efficiency which is covered later.</p> <p>The array can have one or multiple dimensions, each with a size. The importance of these dimensions is explained in the introduction of the memory hierarchy.</p> <a class="reference internal image-reference" href="_images/operational-array.jpg"><img alt="_images/operational-array.jpg" src="_images/operational-array.jpg" style="width: 400px;"/></a> <p>The operational array object has the following attributes:</p> <ul class=simple > <li><p><strong>operational_unit</strong>: The operational unit from which the array is built.</p> <li><p><strong>dimensions</strong>: The dimensions of the array. This should be defined as a Python dictionary, with the keys being the identifier of each dimension of the array (typically ‘D1’, ‘D2’, …) and the values being the size of this dimension (i.e. the size of the array along that dimension).</p> </ul> </section> <section id=memory-instance > <h2 id=memory-instance >Memory Instance<a class=headerlink  href="#memory-instance" title="Permalink to this heading">¶</a></h2> <p>In order to store different activations and weights used for the computations in the operational array, different memory instances are attached in a hierarchical fashion. The instances define how big each memory is in terms of capacity and area, what the cost of writing and reading from these memories is, what its bandwidth is, and how many read/write/read-write ports it includes.</p> <a class="reference internal image-reference" href="_images/memory-instance.jpg"><img alt="_images/memory-instance.jpg" src="_images/memory-instance.jpg" style="width: 400px;"/></a> <p>The memory instance object has the following attributes:</p> <ul class=simple > <li><p><strong>name</strong>: A name for the instance.</p> <li><p><strong>size</strong>: The memory size in bits.</p> <li><p><strong>r_bw/w_bw</strong>: A read or write bandwidth in the number of bits per cycle.</p> <li><p><strong>r_cost/w_cost</strong>: A read or write energy cost.</p> <li><p><strong>area</strong>: Area overhead of the instance.</p> <li><p><strong>r_port/w_port/rw_port</strong>: The number of read/write/read-write ports the instance has available.</p> <li><p><strong>latency</strong>: The latency of memory access in the number of cycles, i.e., after requiring read/write a memory address, how many cycles the memory takes to provide/receive this corresponding data. (For now, this attribute is not actively used. We assume that it is 1 to model the data prefetching behavior thanks to the deterministic dataflow.)</p> </ul> <p>(optional)</p> <ul class=simple > <li><p><strong>min_r_granularity/min_w_granularity</strong>: The minimal memory read/write granularity (in bit) the memory supports. This attribute is used to better model the memory that supports half-word access or quarter-word access patterns. For example, if a memory’s read bandwidth (wordlength) is 256 bit/cycle, its read energy (r_cost) is 100, and its min_r_granularity is 128 bits (i.e., assume this memory allow half-word read), read 128 bits from it (we approximatlly assume that) will only take 50 energy. If min_r_granularity is not defined (or is defined as 256 bits), read 128 bits from it will take 100 energy.</p> </ul> </section> <section id=memory-hierarchy > <h2 id=memory-hierarchy >Memory Hierarchy<a class=headerlink  href="#memory-hierarchy" title="Permalink to this heading">¶</a></h2> <p>Besides knowing what the specs of each memory instance are, the memory hierarchy encodes information with respect to the interconnection of each memory to the operational array, and to other memory instances. This interconnection is achieved through multiple calls to the <cite>add_memory()</cite>, where the first call(s) adds the first level of memories, which connects to the operational array, and later calls connect the higher level of memories to the lower levels’. This builds a hierarchy of memories.</p> <p>To know if the memory should connect to the operational array or another lower memory level, it needs to know which data will be stored within the memories. To decouple the algorithmic side from the hardware side, this is achieved through the concept of ‘memory operands’ (as opposed to ‘algorithmic operands which are typically the Input/Output activations and weights W). You can think of the memory operands as virtual operands, which will later be linked to the actual algorithmic operands in the mapping file through the <cite>memory_operand_links</cite> attribute.</p> <p>Similarly to how the operational unit can be unrolled (forming an operational array), the memories can also be unrolled, where each memory accompanies either a single operational unit or all the operational units in one or more dimensions of the operational array. This is encoded through the <cite>served_dimensions</cite> attribute, which specifies if a single memory instance of this memory level serves all operational units in that dimension. This should be a set of one-hot-encoded tuples.</p> <p>For example, assuming an operational array has 2 dimensions: {D1:3, D2:4}. There are four common <cite>served_dimensions</cite> settings for a memory level: 1. “None” or {(0, 0)}: the memory does not serve any array dimensions, meaning the memory is unrolled with each operational unit, i.e., there are, in total 12 such memory instances. 2. {(1, 0)}: the memory serves array dimension D1, meaning the memory is unrolled with D2, and each memory instance serves all 3 operational units along D1, i.e., there are, in total 4 such memory instances. 3. {(0, 1)}: the memory serves array dimension D2, meaning the memory is unrolled with D1, and each memory instance serves all 4 operational units along D2, i.e., there are, in total 3 such memory instances. 4. “All” or {(1, 0), (0, 1)}: the memory serves all array dimensions, both D1 and D2, meaning the memory is not unrolled with each operational unit but serves all of them, i.e., there are, in total 1 such memory instance.</p> <p>Lastly, the different read/write/read-write ports a memory instance has, are assigned to the different data movements possible in the hierarchy. There are four types of data movements in a memory in the hierarchy: from high (<em>fh</em>), to high (<em>th</em>), from low (<em>fl</em>), to low (<em>tl</em>).</p> <ul class=simple > <li><p><strong>fh</strong>: from high, meaning the data is provided by the higher level of memory to be <strong>written</strong> to the current level of memory</p> <li><p><strong>th</strong>: to high, meaning the data is <strong>read</strong> out from the current level of memory to go to the higher level of memory</p> <li><p><strong>fl</strong>: from low, meaning the data is provided by the lower level of memory to be <strong>written</strong> to the current level of memory</p> <li><p><strong>tl</strong>: to low, meaning the data is <strong>read</strong> out from the current level of memory to go to the lower level of memory</p> </ul> <p>At the time of writing, these can be manually linked to one of the read/write/read-write ports through the following syntax: <cite>{port_type}_port_{port_number}</cite>, <em>port_type</em> being <em>r</em>, <em>w</em> or <em>rw</em> and <em>port_number</em> equal to the port number, starting from 1, which allows allocating multiple ports of the same type. Alternatively, these are automatically generated as a default if not provided to the <cite>add_memory()</cite> call.</p> <p>Internally, the MemoryHierarchy object extends the <a class="reference external" href="https://networkx.org/documentation/stable/reference/classes/digraph.html">NetworkX DiGraph</a> object, so its methods are available.</p> <a class="reference internal image-reference" href="_images/memory-hierarchy.jpg"><img alt="_images/memory-hierarchy.jpg" src="_images/memory-hierarchy.jpg" style="width: 800px;"/></a> <p>The memory hierarchy object includes:</p> <ul class=simple > <li><p><strong>operational_array</strong>: The operational array to which this memory hierarchy will connect. This is required to correctly infer the interconnection through the operational array’s dimensions. Through the <cite>add_memory()</cite> calls it adds a new MemoryLevel to the graph. This requires for each call a:</p> <li><p><strong>memory_instance</strong>: A MemoryInstance object you are adding to the hierarchy.</p> <li><p><strong>operands</strong>: The virtual memory operands this MemoryLevel stores.</p> <li><p><strong>port_alloc</strong>: The directionality of the memory instance’s different ports, as described above.</p> <li><p><strong>served_dimensions</strong>: The different dimensions that this memory level will serve, as described above.</p> </ul> </section> <section id=core > <h2 id=core >Core<a class=headerlink  href="#core" title="Permalink to this heading">¶</a></h2> <p>The operational array and the memory hierarchy together form a core of the accelerator.</p> <a class="reference internal image-reference" href="_images/core.jpg"><img alt="_images/core.jpg" src="_images/core.jpg" style="width: 400px;"/></a> <p>The core object includes:</p> <ul class=simple > <li><p><strong>id</strong>: The id of this core.</p> <li><p><strong>operational_array</strong>: The operational array of this core.</p> <li><p><strong>memory_hierarchy</strong>: The memory hierarchy of this core.</p> </ul> </section> <section id=hw-accelerator-model > <h2 id=hw-accelerator-model >HW Accelerator Model<a class=headerlink  href="#hw-accelerator-model" title="Permalink to this heading">¶</a></h2> <p>Multiple cores are combined together into the HW Accelerator, which is the main object modeling the HW behavior.</p> <p>The accelerator object includes:</p> <ul class=simple > <li><p><strong>name</strong>: A user-defined name for this accelerator.</p> <li><p><strong>core_set</strong>: The set of cores comprised within the accelerator.</p> <li><p><strong>global_buffer</strong>: A memory instance shared across cores. This is currently un-used.</p> </ul> </section> <section id=modelled-examples > <h2 id=modelled-examples >Modelled examples<a class=headerlink  href="#modelled-examples" title="Permalink to this heading">¶</a></h2> <p>In this repository, we have modeled 5 well-known DNN accelerators, which are Meta prototype [1], TPU [2], Edge TPU [3], Ascend [4], Tesla NPU [5], and, for our depth-first scheduling research. To make a fair and relevant comparison, we normalized all of them to have 1024 MACs and maximally 2MB global buffer (GB) but kept their spatial unrolling and local buffer settings, as shown in Table I Idx 1/3/5/7/9. Besides, we constructed a variant of every normalized architecture (by changing its on-chip memory hierarchy), denoted with ‘DF’ in the end of the name, as shown in Table I Idx 2/4/6/8/10.</p> </section> <section id=specific-settings > <h2 id=specific-settings >Specific settings<a class=headerlink  href="#specific-settings" title="Permalink to this heading">¶</a></h2> <a class="reference internal image-reference" href="https://user-images.githubusercontent.com/55059827/183848886-c85b9950-5e49-47c9-8a47-ad05062debc3.png"><img alt="Alternative text" src="https://user-images.githubusercontent.com/55059827/183848886-c85b9950-5e49-47c9-8a47-ad05062debc3.png" style="width: 800px;"/></a> <div class="admonition note"> <p class=admonition-title >Note</p> <p>K is for output channel; C is for input channel; OX and OY are the output feature map’s spatial dimensions; FX and FY are the weight’s spatial dimensions.</p> </div> </section> <section id=references > <h2 id=references >References<a class=headerlink  href="#references" title="Permalink to this heading">¶</a></h2> <p>[1] H. E. Sumbul, T. F. Wu, Y. Li, S. S. Sarwar, W. Koven, E. Murphy- Trotzky, X. Cai, E. Ansari, D. H. Morris, H. Liu, D. Kim, E. Beigne, R. Labs, and Meta, “System-level design and integration of a prototype ar/vr hardware featuring a custom low-power dnn accelerator chip in 7nm technology for codec avatars,” in 2022 IEEE Custom Integrated Circuits Conference (CICC), 2022, pp. 01–08.</p> <p>[2] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia, N. Boden, A. Borchers, R. Boyle, P.-l. Cantin, C. Chao, C. Clark, J. Coriell, M. Daley, M. Dau, J. Dean, B. Gelb, T. V. Ghaemmaghami, R. Gottipati, W. Gulland, R. Hagmann, C. R. Ho, D. Hogberg, J. Hu, R. Hundt, D. Hurt, J. Ibarz, A. Jaffey, A. Jaworski, A. Kaplan, H. Khaitan, D. Killebrew, A. Koch, N. Kumar, S. Lacy, J. Laudon, J. Law, D. Le, C. Leary, Z. Liu, K. Lucke, A. Lundin, G. MacKean, A. Maggiore, M. Mahony, K. Miller, R. Nagarajan, R. Narayanaswami, R. Ni, K. Nix, T. Norrie, M. Omernick, N. Penukonda, A. Phelps, J. Ross, M. Ross, A. Salek, E. Samadiani, C. Severn, G. Sizikov, M. Snelham, J. Souter, D. Steinberg, A. Swing, M. Tan, G. Thorson, B. Tian, H. Toma, E. Tuttle, V. Vasudevan, R. Walter, W. Wang, E. Wilcox, and D. H. Yoon, “In-datacenter performance analysis of a tensor processing unit,” SIGARCH Comput. Archit. News, vol. 45, no. 2, p. 1–12, jun 2017.</p> <p>[3] A. Yazdanbakhsh, K. Seshadri, B. Akin, J. Laudon, and R. Narayanaswami, “An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks,” arXiv e-prints, p. arXiv:2102.10423, Feb. 2021.</p> <p>[4] H. Liao, J. Tu, J. Xia, H. Liu, X. Zhou, H. Yuan, and Y. Hu, “Ascend: a scalable and unified architecture for ubiquitous deep neural network computing : Industry track paper,” in 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA), 2021, pp. 789–801.</p> <p>[5] E. Talpes, D. D. Sarma, G. Venkataramanan, P. Bannon, B. McGee, B. Floering, A. Jalote, C. Hsiong, S. Arora, A. Gorti, and G. S. Sachdev, “Compute solution for tesla’s full self-driving computer,” IEEE Micro, vol. 40, no. 2, pp. 25–35, 2020.</p> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> <a href=workload.html  title=Workload  class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev > <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis > <span class=md-footer-nav__direction > "Previous" </span> Workload </span> </div> </a> <a href=mapping.html  title=Mapping  class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next > <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span class=md-flex__ellipsis > <span class=md-footer-nav__direction > "Next" </span> Mapping </span> </div> <div class="md-flex__cell md-flex__cell--shrink"><i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2022, Arne Symons. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.1.2. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>